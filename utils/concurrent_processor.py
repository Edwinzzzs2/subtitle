import time
import threading
import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue, Empty
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

# é¿å…å¾ªç¯å¯¼å…¥ï¼Œå»¶è¿Ÿå¯¼å…¥watcheræ¨¡å—


@dataclass
class RetryTask:
    """é‡è¯•ä»»åŠ¡æ•°æ®ç»“æ„"""
    filepath: str
    attempt: int
    max_retries: int
    retry_time: datetime
    last_error: Optional[str] = None


class ConcurrentFileProcessor:
    """å¹¶å‘æ–‡ä»¶å¤„ç†å™¨ï¼Œæ”¯æŒå¹¶å‘é‡è¯•æœºåˆ¶"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.retry_queue = Queue()
        self.processing_files = set()  # æ­£åœ¨å¤„ç†çš„æ–‡ä»¶
        self.retry_thread = None
        self.retry_thread_running = False
        self._danmu_downloader = None
        self._lock = threading.Lock()
        
    def start_retry_processor(self):
        """å¯åŠ¨é‡è¯•å¤„ç†çº¿ç¨‹"""
        if self.retry_thread and self.retry_thread.is_alive():
            return
            
        self.retry_thread_running = True
        self.retry_thread = threading.Thread(target=self._retry_processor_loop, daemon=True)
        self.retry_thread.start()
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import log_message
        log_message('info', "ğŸ”„ å¹¶å‘é‡è¯•å¤„ç†å™¨å·²å¯åŠ¨")
        
    def stop_retry_processor(self):
        """åœæ­¢é‡è¯•å¤„ç†çº¿ç¨‹"""
        self.retry_thread_running = False
        if self.retry_thread and self.retry_thread.is_alive():
            self.retry_thread.join(timeout=5)
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import log_message
        log_message('info', "ğŸ›‘ å¹¶å‘é‡è¯•å¤„ç†å™¨å·²åœæ­¢")
        
    def shutdown(self):
        """å…³é—­å¤„ç†å™¨"""
        self.stop_retry_processor()
        self.executor.shutdown(wait=True)
        
    def _get_danmu_downloader(self):
        """è·å–å¼¹å¹•ä¸‹è½½å™¨å®ä¾‹"""
        if self._danmu_downloader is None:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from danmu.danmu_downloader import DanmuDownloader
            from .watcher import get_config
            config = get_config()
            self._danmu_downloader = DanmuDownloader(config)
        return self._danmu_downloader
    
    def _process_video_sync(self, filepath):
        """åŒæ­¥å¤„ç†è§†é¢‘æ–‡ä»¶"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            
            downloader = self._get_danmu_downloader()
            # ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬çš„æ–¹æ³•
            return downloader.process_video_file_sync(filepath)
            
        except Exception as e:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('error', f"åŒæ­¥å¤„ç†è§†é¢‘æ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {e}")
            return {
                'success': False,
                'message': f'å¤„ç†å¤±è´¥: {str(e)}',
                'video_file': filepath
            }
        
    def _retry_processor_loop(self):
        """é‡è¯•å¤„ç†å¾ªç¯"""
        while self.retry_thread_running:
            try:
                # æ”¶é›†åˆ°æœŸçš„é‡è¯•ä»»åŠ¡
                ready_tasks = []
                current_time = datetime.now()
                
                # ä»é˜Ÿåˆ—ä¸­å–å‡ºæ‰€æœ‰åˆ°æœŸçš„ä»»åŠ¡
                temp_tasks = []
                while True:
                    try:
                        task = self.retry_queue.get_nowait()
                        if task.retry_time <= current_time:
                            ready_tasks.append(task)
                        else:
                            temp_tasks.append(task)
                    except Empty:
                        break
                
                # å°†æœªåˆ°æœŸçš„ä»»åŠ¡æ”¾å›é˜Ÿåˆ—
                for task in temp_tasks:
                    self.retry_queue.put(task)
                
                # å¹¶å‘å¤„ç†åˆ°æœŸçš„é‡è¯•ä»»åŠ¡
                if ready_tasks:
                    # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                    from .watcher import log_message
                    log_message('info', f"ğŸ”„ å¼€å§‹å¹¶å‘é‡è¯• {len(ready_tasks)} ä¸ªæ–‡ä»¶")
                    self._process_retry_tasks_concurrently(ready_tasks)
                
                # çŸ­æš‚ä¼‘çœ ï¼Œé¿å…è¿‡åº¦å ç”¨CPU
                time.sleep(1)
                
            except Exception as e:
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                from .watcher import log_message
                log_message('error', f"âŒ é‡è¯•å¤„ç†å¾ªç¯å‡ºé”™: {e}")
                time.sleep(5)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                
    def _process_retry_tasks_concurrently(self, tasks: List[RetryTask]):
        """å¹¶å‘å¤„ç†é‡è¯•ä»»åŠ¡"""
        if not tasks:
            return
            
        # æ£€æŸ¥çº¿ç¨‹æ± æ˜¯å¦å·²å…³é—­
        if self.executor._shutdown:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('warning', f"âš ï¸ çº¿ç¨‹æ± å·²å…³é—­ï¼Œæ— æ³•å¤„ç† {len(tasks)} ä¸ªé‡è¯•ä»»åŠ¡")
            return
            
        # æäº¤æ‰€æœ‰é‡è¯•ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        future_to_task = {}
        for task in tasks:
            try:
                future = self.executor.submit(self._process_single_retry_task, task)
                future_to_task[future] = task
            except RuntimeError as e:
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                from .watcher import log_message
                log_message('warning', f"âš ï¸ æ— æ³•æäº¤é‡è¯•ä»»åŠ¡: {task.filepath}, é”™è¯¯: {e}")
            
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            try:
                success, result = future.result()
                if not success and task.attempt < task.max_retries:
                    # é‡è¯•å¤±è´¥ï¼Œé‡æ–°åŠ å…¥é‡è¯•é˜Ÿåˆ—
                    self._schedule_retry(task.filepath, task.attempt + 1, task.max_retries, result.get('message', 'Unknown error'))
            except Exception as e:
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                from .watcher import log_message
                log_message('error', f"âŒ é‡è¯•ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {task.filepath}, é”™è¯¯: {e}")
                
    def _process_single_retry_task(self, task: RetryTask) -> Tuple[bool, Dict[str, Any]]:
        """å¤„ç†å•ä¸ªé‡è¯•ä»»åŠ¡"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('debug', f"ğŸ”„ é‡è¯•å¤„ç†æ–‡ä»¶ (å°è¯• {task.attempt}/{task.max_retries}): {task.filepath}")
            
            # åŒæ­¥å¤„ç†å¼¹å¹•ä¸‹è½½
            result = self._process_video_sync(task.filepath)
            
            if result and result.get('success'):
                with self._lock:
                    _processed_files.add(task.filepath)
                    
                if result.get('skipped'):
                    log_message('info', f"â© å¼¹å¹•æ–‡ä»¶å·²å­˜åœ¨: {task.filepath}")
                else:
                    # è·å–ä¸‹è½½çš„å¼¹å¹•æ–‡ä»¶ä¿¡æ¯
                    downloaded_files = result.get('downloaded_files', [])
                    if downloaded_files:
                        import os
                        file_paths = [os.path.relpath(f['file_path'], '.') for f in downloaded_files]
                        provider_info = ', '.join(file_paths)
                    else:
                        provider_info = 'Unknown'
                    
                    log_message('info', f"âœ… é‡è¯•æˆåŠŸ - å¼¹å¹•ä¸‹è½½å®Œæˆ: {task.filepath} -> {provider_info} -> ğŸ“Š (å¼¹å¹•æ•°é‡: {result.get('danmu_count', 0)} æ¡)")
                    
                    # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                    self._update_last_update_time()
                    
                return True, result
            else:
                error_msg = result.get('message', 'Unknown error') if result else 'No result'
                log_message('error', f"âŒ é‡è¯•å¤±è´¥: {task.filepath} | {error_msg}")
                return False, result or {'message': error_msg}
                
        except Exception as e:
            log_message('error', f"âŒ é‡è¯•å¤„ç†å¼‚å¸¸: {task.filepath}, é”™è¯¯: {e}")
            return False, {'message': str(e)}
            
    def _update_last_update_time(self):
        """æ›´æ–°æœ€åæ›´æ–°æ—¶é—´"""
        try:
            from datetime import datetime
            import pytz
            import utils.watcher as watcher_module
            beijing_tz = pytz.timezone('Asia/Shanghai')
            watcher_module._last_update_time = datetime.now(beijing_tz)
        except Exception as e:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('error', f"âŒ æ›´æ–°æ—¶é—´å¤±è´¥: {e}")
            
    def _schedule_retry(self, filepath: str, attempt: int, max_retries: int, error_msg: str = None):
        """å®‰æ’é‡è¯•ä»»åŠ¡"""
        if attempt > max_retries:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('error', f"âŒ æ–‡ä»¶å¤„ç†æœ€ç»ˆå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {filepath}")
            return
            
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import get_config
        config = get_config()
        retry_delay = config.get('retry_delay', 1.0)
        retry_time = datetime.now() + timedelta(seconds=retry_delay)
        
        retry_task = RetryTask(
            filepath=filepath,
            attempt=attempt,
            max_retries=max_retries,
            retry_time=retry_time,
            last_error=error_msg
        )
        
        self.retry_queue.put(retry_task)
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import log_message
        log_message('info', f"â±ï¸ å·²å®‰æ’é‡è¯•: {filepath} (å°è¯• {attempt}/{max_retries}ï¼Œ{retry_delay}ç§’åæ‰§è¡Œ)")
        
    def process_file_concurrent(self, filepath: str) -> bool:
        """å¹¶å‘å¤„ç†å•ä¸ªæ–‡ä»¶"""
        if filepath in self.processing_files:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('debug', f"â­ï¸ æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡: {filepath}")
            return False
            
        # æ£€æŸ¥çº¿ç¨‹æ± æ˜¯å¦å·²å…³é—­
        if self.executor._shutdown:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('warning', f"âš ï¸ çº¿ç¨‹æ± å·²å…³é—­ï¼Œæ— æ³•å¤„ç†æ–‡ä»¶: {filepath}")
            return False
            
        with self._lock:
            self.processing_files.add(filepath)
            
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import get_config
            config = get_config()
            max_retries = config.get('max_retries', 3)
            
            # æäº¤åˆ°çº¿ç¨‹æ± å¤„ç†
            future = self.executor.submit(self._process_single_file, filepath, max_retries)
            
            # ä¸ç­‰å¾…ç»“æœï¼Œè®©å®ƒå¼‚æ­¥æ‰§è¡Œ
            def handle_result(fut):
                try:
                    success, result = fut.result()
                    if not success:
                        # å¤„ç†å¤±è´¥ï¼Œå®‰æ’é‡è¯•
                        self._schedule_retry(filepath, 2, max_retries, result.get('message', 'Unknown error'))
                finally:
                    with self._lock:
                        self.processing_files.discard(filepath)
                        
            future.add_done_callback(handle_result)
            return True
            
        except Exception as e:
            with self._lock:
                self.processing_files.discard(filepath)
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('error', f"âŒ æäº¤æ–‡ä»¶å¤„ç†ä»»åŠ¡å¤±è´¥: {filepath}, é”™è¯¯: {e}")
            return False
            
    def _process_single_file(self, filepath: str, max_retries: int) -> Tuple[bool, Dict[str, Any]]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆé¦–æ¬¡å°è¯•ï¼‰"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
            from .watcher import log_message
            log_message('debug', f"ğŸ”„ å¤„ç†è§†é¢‘æ–‡ä»¶ (å°è¯• 1/{max_retries}): {filepath}")
            
            # åŒæ­¥å¤„ç†å¼¹å¹•ä¸‹è½½
            result = self._process_video_sync(filepath)
            
            if result and result.get('success'):
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                from .watcher import _processed_files
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                from .watcher import _processed_files
                with self._lock:
                    _processed_files.add(filepath)
                    
                if result.get('skipped'):
                    log_message('info', f"â© å¼¹å¹•æ–‡ä»¶å·²å­˜åœ¨: {filepath}")
                else:
                    # è·å–ä¸‹è½½çš„å¼¹å¹•æ–‡ä»¶ä¿¡æ¯
                    downloaded_files = result.get('downloaded_files', [])
                    if downloaded_files:
                        import os
                        file_paths = [os.path.relpath(f['file_path'], '.') for f in downloaded_files]
                        provider_info = ', '.join(file_paths)
                    else:
                        provider_info = 'Unknown'
                    
                    log_message('info', f"âœ… å¼¹å¹•ä¸‹è½½å®Œæˆ: {filepath} -> {provider_info} -> ğŸ“Š (å¼¹å¹•æ•°é‡: {result.get('danmu_count', 0)} æ¡)")
                    
                    # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                    self._update_last_update_time()
                    
                return True, result
            else:
                error_msg = result.get('message', 'Unknown error') if result else 'No result'
                log_message('error', f"âŒ å¼¹å¹•ä¸‹è½½å¤±è´¥: {filepath} | {error_msg}")
                return False, result or {'message': error_msg}
                
        except Exception as e:
            log_message('error', f"âŒ å¤„ç†è§†é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {filepath}, é”™è¯¯: {e}")
            return False, {'message': str(e)}
            
    def process_files_batch(self, filepaths: List[str]) -> int:
        """æ‰¹é‡å¹¶å‘å¤„ç†æ–‡ä»¶"""
        if not filepaths:
            return 0
            
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import log_message
        log_message('info', f"ğŸš€ å¼€å§‹å¹¶å‘å¤„ç† {len(filepaths)} ä¸ªæ–‡ä»¶")
        
        success_count = 0
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import get_config
        config = get_config()
        max_retries = config.get('max_retries', 3)
        
        # æäº¤æ‰€æœ‰æ–‡ä»¶åˆ°çº¿ç¨‹æ± 
        future_to_filepath = {}
        for filepath in filepaths:
            if filepath not in self.processing_files:
                with self._lock:
                    self.processing_files.add(filepath)
                future = self.executor.submit(self._process_single_file, filepath, max_retries)
                future_to_filepath[future] = filepath
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in as_completed(future_to_filepath):
            filepath = future_to_filepath[future]
            try:
                success, result = future.result()
                if success:
                    success_count += 1
                else:
                    # å¤„ç†å¤±è´¥ï¼Œå®‰æ’é‡è¯•
                    self._schedule_retry(filepath, 2, max_retries, result.get('message', 'Unknown error'))
            except Exception as e:
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
                from .watcher import log_message
                log_message('error', f"âŒ æ‰¹é‡å¤„ç†ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {filepath}, é”™è¯¯: {e}")
            finally:
                with self._lock:
                    self.processing_files.discard(filepath)
                    
        log_message('info', f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ {success_count}/{len(filepaths)} ä¸ªæ–‡ä»¶")
        return success_count
        
    def get_status(self) -> Dict[str, Any]:
        """è·å–å¤„ç†å™¨çŠ¶æ€"""
        return {
            'processing_count': len(self.processing_files),
            'retry_queue_size': self.retry_queue.qsize(),
            'retry_processor_running': self.retry_thread_running,
            'max_workers': self.max_workers
        }


# å…¨å±€å¹¶å‘å¤„ç†å™¨å®ä¾‹
_concurrent_processor: Optional[ConcurrentFileProcessor] = None


def get_concurrent_processor() -> ConcurrentFileProcessor:
    """è·å–å…¨å±€å¹¶å‘å¤„ç†å™¨å®ä¾‹"""
    global _concurrent_processor
    # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
    from .watcher import get_config
    config = get_config()
    max_workers = config.get('max_concurrent_workers', 4)  # å¯é…ç½®çš„å¹¶å‘æ•°
    
    # å¦‚æœå¤„ç†å™¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„
    if _concurrent_processor is None:
        _concurrent_processor = ConcurrentFileProcessor(max_workers=max_workers)
        _concurrent_processor.start_retry_processor()
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import log_message
        log_message('info', f"ğŸš€ å¹¶å‘å¤„ç†å™¨å·²å¯åŠ¨ï¼Œå·¥ä½œçº¿ç¨‹æ•°: {max_workers}")
    # å¦‚æœå¹¶å‘æ•°é…ç½®å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°åˆ›å»º
    elif _concurrent_processor.max_workers != max_workers:
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥
        from .watcher import log_message
        log_message('info', f"ğŸ”„ å¹¶å‘æ•°é…ç½®å˜æ›´ ({_concurrent_processor.max_workers} -> {max_workers})ï¼Œé‡æ–°åˆå§‹åŒ–å¤„ç†å™¨")
        old_processor = _concurrent_processor
        # å…ˆåˆ›å»ºæ–°çš„å¤„ç†å™¨
        _concurrent_processor = ConcurrentFileProcessor(max_workers=max_workers)
        _concurrent_processor.start_retry_processor()
        # å†å…³é—­æ—§çš„å¤„ç†å™¨
        old_processor.shutdown()
        log_message('info', f"ğŸš€ å¹¶å‘å¤„ç†å™¨å·²é‡æ–°å¯åŠ¨ï¼Œå·¥ä½œçº¿ç¨‹æ•°: {max_workers}")
    
    return _concurrent_processor


def shutdown_concurrent_processor():
    """å…³é—­å…¨å±€å¹¶å‘å¤„ç†å™¨"""
    global _concurrent_processor
    if _concurrent_processor:
        _concurrent_processor.shutdown()
        _concurrent_processor = None